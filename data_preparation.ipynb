{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dbadebd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e3e86c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "data_dir = os.path.join(current_dir, \"data\")\n",
    "dta_path = os.path.join(data_dir, \"DDCGdata_final.dta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4d8150",
   "metadata": {},
   "source": [
    "### For map graphic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "25d29523",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josep\\AppData\\Local\\Temp\\ipykernel_20184\\3505542546.py:1: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  df = pd.read_stata(dta_path)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_stata(dta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "13ebbb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial1 = df[['country_name', 'wbcode', 'year', 'yeardem', 'dem', 'yearrev', 'region']]\n",
    "trial1 = trial1.rename(columns={\n",
    "    'country_name': 'name',\n",
    "    'wbcode': 'code'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "12d0d003",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis1_dir=os.path.join(current_dir, \"final_html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "78085a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = os.path.join(vis1_dir, \"trial1.csv\")\n",
    "#trial1.to_csv(csv_path, index=False)\n",
    "trial1.loc[trial1[\"code\"] == \"ZAR\", \"code\"] = \"COD\"\n",
    "\n",
    "#Correctiong of the map\n",
    "non_afr = [\"AFG\", \"YEM\", \"OMN\", \"SAU\", \"QAT\", \"BHR\", \"KWT\", \"UAE\",\n",
    "           \"IRQ\", \"IRN\", \"JOR\", \"SYR\", \"LBN\", \"PAK\"]\n",
    "\n",
    "trial1.loc[trial1[\"code\"].isin(non_afr), \"region\"] = \"NO-AFR\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d93d4215",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the information for LAC\n",
    "LAC = trial1[trial1[\"region\"].isin([\"LAC\"])]\n",
    "LAC=LAC.rename(columns={'code': 'id'})\n",
    "lac_path = os.path.join(vis1_dir, \"lac.csv\")\n",
    "LAC.to_csv(lac_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f9e2b160",
   "metadata": {},
   "outputs": [],
   "source": [
    "lac_2010 = LAC[LAC[\"year\"] == 2010]\n",
    "lac_2010_path = os.path.join(vis1_dir, \"lac_2010.csv\")\n",
    "lac_2010.to_csv(lac_2010_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "51d658ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the information for Africa\n",
    "AFR = trial1[trial1[\"region\"].isin([\"AFR\", \"MNA\"])]\n",
    "AFR=AFR.rename(columns={'code': 'id'})\n",
    "afr_path = os.path.join(vis1_dir, \"afr.csv\")\n",
    "AFR.to_csv(afr_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6301fe37",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial1 = trial1.drop(columns=['yeardem'])\n",
    "trial1 = trial1.rename(columns={'dem': 'yeardem'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6817ec",
   "metadata": {},
   "source": [
    "### For inequality/Repression graphic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1e1cbcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"data/V-Dem-CY-Core-v15.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "673906d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "repression=df[['country_name', 'country_text_id', 'year', 'v2csreprss', 'v2x_libdem']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7e10530a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_stata(\"data/swiid9_9.dta\")\n",
    "df.loc[df[\"country\"] == \"United States\", \"country\"] = \"United States of America\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d6cbbeef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josep\\AppData\\Local\\Temp\\ipykernel_20184\\2527003196.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"gini_disp_mean\"] = df[gini_cols].mean(axis=1)\n"
     ]
    }
   ],
   "source": [
    "#IA: how to gete the average of multiple columns that start with the same name like gini_disp1, gin_disp2, etc. in pandas\n",
    "gini_cols = df.filter(regex=r\"^_\\d+_gini_disp$\").columns\n",
    "\n",
    "df[\"gini_disp_mean\"] = df[gini_cols].mean(axis=1)\n",
    "\n",
    "df_clean = df[[\"country\", \"year\", \"gini_disp_mean\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8c0566f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging the datasets\n",
    "merged_df = pd.merge(repression, df_clean, left_on=['country_name', 'year'], right_on=['country', 'year'], how='inner')\n",
    "\n",
    "#IA: How to create a category variable in pandas based on the values of another continues variable\n",
    "def classify_libdem(value):\n",
    "    if value < 0.25:\n",
    "        return 'Autocratic'\n",
    "    elif 0.25 <= value < 0.5:\n",
    "        return 'Electoral Authoritarian'\n",
    "    elif 0.5 <= value < 0.75:\n",
    "        return 'Minimally Democratic'\n",
    "    else:\n",
    "        return 'Democratic'\n",
    "    \n",
    "merged_df['class'] = merged_df['v2x_libdem'].apply(classify_libdem) \n",
    "#Only keep 1990 onwards\n",
    "inequality_repression = merged_df[merged_df['year'] >= 1980]\n",
    "inequality_repression = inequality_repression[inequality_repression['year'] < 2021]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c01623a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = os.path.join(vis1_dir, \"scatter.csv\")\n",
    "inequality_repression.to_csv(csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a2f77f",
   "metadata": {},
   "source": [
    "## Creating new GeoJson for Africa and LATAM   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "812964ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6d498a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id                  name  \\\n",
      "0  AFG           Afghanistan   \n",
      "1  AGO                Angola   \n",
      "2  ALB               Albania   \n",
      "3  ARE  United Arab Emirates   \n",
      "4  ARG             Argentina   \n",
      "\n",
      "                                            geometry  \n",
      "0  POLYGON ((61.21082 35.65007, 62.23065 35.27066...  \n",
      "1  MULTIPOLYGON (((16.32653 -5.87747, 16.57318 -6...  \n",
      "2  POLYGON ((20.59025 41.8554, 20.46318 41.51509,...  \n",
      "3  POLYGON ((51.57952 24.2455, 51.75744 24.29407,...  \n",
      "4  MULTIPOLYGON (((-65.5 -55.2, -66.45 -55.25, -6...  \n",
      "CRS: EPSG:4326\n"
     ]
    }
   ],
   "source": [
    "data_dir = Path(data_dir)\n",
    "vis1_dir=Path(vis1_dir)\n",
    "fp = data_dir/\"world.geojson\"\n",
    "gdf = gpd.read_file(fp)\n",
    "print(gdf.head())\n",
    "print(\"CRS:\", gdf.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8c4cc432",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf[\"id_key\"] = gdf[\"id\"].astype(str).str.zfill(3)  \n",
    "trial1[\"code_key\"] = trial1[\"code\"].astype(str).str.zfill(3)\n",
    "gdf = gdf.merge(trial1[[\"code_key\", \"region\"]], left_on=\"id_key\", right_on=\"code_key\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a83220b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAC = gdf[gdf[\"region\"].isin([\"LAC\"])]\n",
    "out_path = vis1_dir / \"lac.geojson\"\n",
    "LAC.to_file(out_path, driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e2491ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "AFR = gdf[gdf[\"region\"].isin([\"AFR\", \"MNA\"])]\n",
    "out_path = vis1_dir / \"afr.geojson\"\n",
    "AFR.to_file(out_path, driver=\"GeoJSON\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
